{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from matplotlib import gridspec \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the csv file using pandas \n",
    "# best way is to mount the drive on colab and  \n",
    "# copy the path for the csv file \n",
    "data = pd.read_csv(\"creditcard.csv\") \n",
    "data = data.sample(frac=0.1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0017234102419808666\n",
      "Fraud Cases: 49\n",
      "Valid Transactions: 28432\n"
     ]
    }
   ],
   "source": [
    "# Determine number of fraud cases in dataset \n",
    "fraud = data[data['Class'] == 1] \n",
    "valid = data[data['Class'] == 0] \n",
    "outlierFraction = len(fraud)/float(len(valid)) \n",
    "print(outlierFraction) \n",
    "print('Fraud Cases: {}'.format(len(data[data['Class'] == 1]))) \n",
    "print('Valid Transactions: {}'.format(len(data[data['Class'] == 0]))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28481, 30)\n",
      "(28481,)\n"
     ]
    }
   ],
   "source": [
    "# dividing the X and the Y from the dataset \n",
    "X = data.drop(['Class'], axis = 1) \n",
    "Y = data[\"Class\"] \n",
    "print(X.shape) \n",
    "print(Y.shape) \n",
    "# getting just the values for the sake of processing \n",
    "# (its a numpy array with no columns) \n",
    "xData = X.values \n",
    "yData = Y.values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets \n",
    "from sklearn.model_selection import train_test_split \n",
    "# Split the data into training and testing sets \n",
    "xTrain, xTest, yTrain, yTest = train_test_split(xData, yData, test_size = 0.2, random_state = 42) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Random Forest Classifier (RANDOM FOREST) \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "# random forest model creation \n",
    "rfc = RandomForestClassifier() \n",
    "rfc.fit(xTrain, yTrain) \n",
    "# predictions \n",
    "yPred = rfc.predict(xTest) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model used is Random Forest classifier\n",
      "The accuracy is 0.9991223450939091\n",
      "The precision is 0.6666666666666666\n",
      "The recall is 0.5714285714285714\n",
      "The F1-Score is 0.6153846153846153\n",
      "The Matthews correlation coefficient is0.6167795469266656\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the classifier \n",
    "# printing every score of the classifier \n",
    "# scoring in anything \n",
    "from sklearn.metrics import classification_report, accuracy_score \n",
    "from sklearn.metrics import precision_score, recall_score \n",
    "from sklearn.metrics import f1_score, matthews_corrcoef \n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "n_outliers = len(fraud) \n",
    "n_errors = (yPred != yTest).sum() \n",
    "print(\"The model used is Random Forest classifier\") \n",
    "\n",
    "acc = accuracy_score(yTest, yPred) \n",
    "print(\"The accuracy is {}\".format(acc)) \n",
    "\n",
    "prec = precision_score(yTest, yPred) \n",
    "print(\"The precision is {}\".format(prec)) \n",
    "\n",
    "rec = recall_score(yTest, yPred) \n",
    "print(\"The recall is {}\".format(rec)) \n",
    "\n",
    "f1 = f1_score(yTest, yPred) \n",
    "print(\"The F1-Score is {}\".format(f1)) \n",
    "\n",
    "MCC = matthews_corrcoef(yTest, yPred) \n",
    "print(\"The Matthews correlation coefficient is{}\".format(MCC)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5943d1bfe3f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
